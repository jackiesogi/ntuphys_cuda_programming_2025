># Introduction to CUDA Parallel Programming HW5
```
Author: NTUST M11315133 陳首吉
Date: June 6, 2025
```

## Implementation

The kernel function `temperature_update_kernel()` updates each grid point in parallel using the Jacobi update rule. Each thread computes its global index and determines its corresponding 2D coordinates. Interior points are updated based on the average of their four neighbors. Boundary conditions are respected by skipping edge points.

```cpp
__global__ void temperature_update_kernel(float* new_temperature_d,
                                          const float* old_temperature_d,
                                          int start_index) {
    int global_idx = blockIdx.x * blockDim.x + threadIdx.x + start_index;
    int row = global_idx / GRID_SIZE;
    int col = global_idx % GRID_SIZE;

    if (row > 0 && row < GRID_SIZE - 1 && col > 0 && col < GRID_SIZE - 1) {
        new_temperature_d[global_idx] = 0.25f *
        (old_temperature_d[global_idx - 1] + old_temperature_d[global_idx + 1] +
        old_temperature_d[global_idx - GRID_SIZE] + old_temperature_d[global_idx + GRID_SIZE]);
    }
}
```

### Boundary Conditions

- **Top boundary** $(i = 0)$: $T = 400 \, \text{K}$
- **Bottom** $(i = L-1)$, **Left** $(j = 0)$, and **Right** $(j = L-1)$: $T = 273 \, \text{K}$

### Convergence Criterion

The algorithm halts when the maximum pointwise difference between two successive iterations meets:

$$
\max_{i,j} \left| T_{i,j}^{(k+1)} - T_{i,j}^{(k)} \right| < 10^{-3}
$$

or if the number of iterations exceeds 100,000.

---

## Experiment Results

**Test Setup:**

- Grid size: 1024 x 1024
- Metric: GFLOPS (Billion Floating Point Operations per Second)

### Performance Summary Table

#### 2 GPUs

| TPB  | BPG    | H2D Time (s) | Kernel Time (s) | D2H Time (s) | Total Time (s) | GFLOPS |
| ---- | ------ | ------------ | --------------- | ------------ | -------------- | ------ |
| 1024 | 512    | 34.94        | 3.80            | 17.26        | 56.00          | 3.73   |
| 512  | 1024   | 34.85        | 3.50            | 17.20        | 55.55          | 3.76   |
| 256  | 2048   | 34.70        | 3.44            | 17.15        | 55.29          | 3.78   |
| 128  | 4096   | 34.90        | 3.45            | 17.22        | 55.57          | 3.76   |
| 64   | 8192   | 34.80        | 3.60            | 17.21        | 55.61          | 3.75   |
| 32   | 16384  | 34.95        | 5.24            | 17.19        | 57.38          | 3.66   |
| 16   | 32768  | 34.87        | 9.37            | 17.18        | 61.42          | 3.42   |
| 8    | 65536  | 34.73        | 18.21           | 17.17        | 70.11          | 3.00   |
| 4    | 131072 | 34.91        | 34.30           | 17.23        | 86.44          | 2.44   |
| 2    | 262144 | 34.89        | 67.90           | 17.19        | 120.00         | 1.76   |
| 1    | 524288 | 35.00        | 134.02          | 17.19        | 186.21         | 1.13   |

#### 1 GPU

| TPB  | BPG     | H2D Time (s) | Kernel Time (s) | D2H Time (s) | Total Time (s) | GFLOPS |
| ---- | ------- | ------------ | --------------- | ------------ | -------------- | ------ |
| 1024 | 1024    | 33.92        | 6.95            | 33.07        | 73.94          | 2.84   |
| 512  | 2048    | 34.20        | 6.83            | 33.02        | 74.05          | 2.84   |
| 256  | 4096    | 33.97        | 6.70            | 32.96        | 73.63          | 2.86   |
| 128  | 8192    | 33.99        | 6.72            | 32.98        | 73.69          | 2.86   |
| 64   | 16384   | 34.01        | 6.82            | 33.05        | 73.88          | 2.85   |
| 32   | 32768   | 33.95        | 9.83            | 33.03        | 76.81          | 2.74   |
| 16   | 65536   | 33.91        | 18.38           | 33.00        | 85.29          | 2.47   |
| 8    | 131072  | 33.93        | 36.78           | 32.96        | 103.67         | 2.03   |
| 4    | 262144  | 33.92        | 68.99           | 32.95        | 135.86         | 1.55   |
| 2    | 524288  | 33.96        | 136.94          | 33.00        | 203.90         | 1.03   |
| 1    | 1048576 | 34.01        | 270.84          | 33.02        | 337.87         | 0.62   |

---

## Discussion

- The iterative solver did not reach convergence within the 100,000 iteration cap.
- With 2 GPUs, we observed about 33% speedup at optimal settings compared to 1 GPU.
- Best performance (GFLOPS) was achieved at a thread block size of 256, indicating this configuration balances occupancy and memory bandwidth.
- The majority of time was spent on data transfer rather than computation, indicating memory optimizations could yield significant gains.
- Performance decreased significantly for low TPB values due to increased kernel launch overhead and underutilization of GPU cores.

