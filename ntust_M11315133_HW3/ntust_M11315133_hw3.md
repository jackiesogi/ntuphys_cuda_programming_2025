># Introduction to CUDA Parallel Programming HW3
```
Author: NTUST M11315133 陳首吉
Date: June 2, 2025
```

## Implementation

### 1. CUDA Kernel Function

This is the core CUDA kernel that updates each point in a 3D cube using a 6-point average stencil, simulating an iterative PDE solver. Performance is sensitive to block/grid configuration.

```cpp
__global__ void compute_phi(float* phi, float* phi_new, int N) {
    int x = blockIdx.x * blockDim.x + threadIdx.x;
    int y = blockIdx.y * blockDim.y + threadIdx.y;
    int z = blockIdx.z * blockDim.z + threadIdx.z;

    if (x > 0 && x < N-1 && y > 0 && y < N-1 && z > 0 && z < N-1) {
        int idx = x + y * N + z * N * N;
        phi_new[idx] = (phi[idx - 1] + phi[idx + 1] +
                        phi[idx - N] + phi[idx + N] +
                        phi[idx - N*N] + phi[idx + N*N]) / 6.0f;
    }
}
```

## Summary Table

| Cube Size      | Iterations | Kernel Time (ms) | CPU Time (ms) | GPU Speedup (With Transfer) | GPU GFLOPS | CPU GFLOPS |
|----------------|------------|------------------|---------------|------------------------------|------------|------------|
| 8 × 8 × 8      | 64         | 0.616320         | 0.034000      | 0.06×                        | 0.372170   | 6.746353   |
| 16 × 16 × 16   | 256        | 2.848928         | 0.905000      | 0.32×                        | 2.576419   | 8.110533   |
| 32 × 32 × 32   | 1024       | 33.816734        | 24.577999     | 0.73×                        | 6.945704   | 9.556556   |
| 64 × 64 × 64   | 4096       | 712.808655       | 988.765991    | 1.39×                        | 10.544475  | 7.601589   |

## Observations

- For smaller cube sizes (8³, 16³), the CPU is significantly faster than the GPU.
- For medium size (32³), GPU starts to catch up, but still slightly slower.
- For large size (64³), GPU outperforms CPU with a speedup of **1.39×**.
- The GPU's GFLOPS scales with the problem size, showing better utilization for large datasets.
- Data transfer time (Host ↔ Device) is negligible compared to kernel execution time for larger sizes.

## Convergence (`avg_phi`) over Iterations

### 8³ Cube
```
r = 1, avg_phi = 0.044281
...
r = 7, avg_phi = 0.000000
```

### 16³ Cube
```
r = 1, avg_phi = 0.056020
...
r = 14, avg_phi = 0.000000
```

### 32³ Cube
```
r = 1, avg_phi = 0.060927
...
r = 28, avg_phi = 0.000000
```

### 64³ Cube
```
r = 1, avg_phi = 0.061259
...
r = 55, avg_phi = 0.000000
```

## Conclusion

- CPU performance dominates for small problems due to low overhead and fast cache access.
- GPU becomes advantageous only when the problem size is large enough to amortize data transfer and launch overhead.
- For cube sizes ≥ 64³, GPU starts to demonstrate clear advantages.
- Optimal execution model should be chosen based on problem size and target performance metric.
